======================INSTALL DOCKER 1.9.X WITH NVIDIA DOCKER RUNTIME=============================================

[Ref: https://github.com/NVIDIA/nvidia-docker]
distribution=$(. /etc/os-release;echo $ID$VERSION_ID)
curl -s -L https://nvidia.github.io/nvidia-docker/gpgkey | sudo apt-key add -
curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.list | sudo tee /etc/apt/sources.list.d/nvidia-docker.list

sudo apt-get update && sudo apt-get install -y nvidia-docker2
sudo systemctl restart docker


Connect to your MasterNode and set nvidia as the default run inÂ /etc/docker/daemon.json:
{
    "default-runtime": "nvidia",
    "runtimes": {
        "nvidia": {
            "path": "/usr/bin/nvidia-container-runtime",
            "runtimeArgs": []
        }
    }
}

sudo systemctl restart docker

docker build -t nvidia/k8s-device-plugin:1.0.0-beta4 https://github.com/NVIDIA/k8s-device-plugin.git#1.0.0-beta4


====================INSTALL AND SETUP KUBERNETES 1.15==============================================================
CALICO:

kubeadm reset
iptables -F && iptables -t nat -F && iptables -t mangle -F && iptables -X
sudo kubeadm init --pod-network-cidr=192.168.0.0/16

mkdir -p $HOME/.kube
sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
sudo chown $(id -u):$(id -g) $HOME/.kube/config

kubectl apply -f \
https://docs.projectcalico.org/v3.4/getting-started/kubernetes/installation/hosted/etcd.yaml

kubectl apply -f \
https://docs.projectcalico.org/v3.4/getting-started/kubernetes/installation/hosted/calico.yaml

UNINSTALL & REINSTALL KUBERNETES:
sudo -s
kubeadm reset
apt-get purge kubeadm kubectl kubelet kubernetes-cni kube*   
apt-get autoremove  
sudo rm -rf ~/.kube

kubectl drain <node name> --delete-local-data --force --ignore-daemonsets
kubectl delete node <node name>

curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -
cat <<EOF >/etc/apt/sources.list.d/kubernetes.list
deb http://apt.kubernetes.io/ kubernetes-xenial main
EOF
apt-get update
apt-get install -y kubeadm=1.15.0-00 kubectl=1.15.0-00 kubelet=1.15.0-00 kubernetes-cni=0.7.5-00




FLANNEL:

kubeadm reset
iptables -F && iptables -t nat -F && iptables -t mangle -F && iptables -X
ipvsadm --clear
systemctl daemon-reload
systemctl restart kubelet
systemctl restart docker

sudo kubeadm init --pod-network-cidr=10.244.0.0/16

mkdir -p $HOME/.kube
sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
sudo chown $(id -u):$(id -g) $HOME/.kube/config

kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/2140ac876ef134e0ed5af15c65e414cf26827915/Documentation/kube-flannel.yml

kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml

kubeadm join 192.168.1.243:6443 --token mypcum.s5pn2ldbhr69xor2 --discovery-token-ca-cert-hash sha256:082e8e5311d48432cc1453890710c38c085e6cb183e6603e2e9d4c9ac1b5307e

kubectl taint nodes --all node-role.kubernetes.io/master-

apt-mark hold kubelet kubeadm kubectl

kubectl get all --all-namespaces


=================================INSTALL NVIDIA DEVICE PLUGIN FOR KUBERNTES FOR LETTING K8S PODS ACCESS GPU=================

https://github.com/NVIDIA/k8s-device-plugin

kubectl create -f https://raw.githubusercontent.com/NVIDIA/k8s-device-plugin/1.0.0-beta4/nvidia-device-plugin.yml


COREDNS ERROR:


kubectl logs coredns-5c98db65d4-qv5tm -n kube-system
.:53
2019-12-27T14:42:43.802Z [INFO] CoreDNS-1.3.1
2019-12-27T14:42:43.802Z [INFO] linux/amd64, go1.11.4, 6b56a9c
CoreDNS-1.3.1
linux/amd64, go1.11.4, 6b56a9c
2019-12-27T14:42:43.802Z [INFO] plugin/reload: Running configuration MD5 = 5d5369fbc12f985709b924e721217843
2019-12-27T14:42:43.803Z [FATAL] plugin/loop: Loop (127.0.0.1:53754 -> :53) detected for zone ".", see https://coredns.io/plugins/loop#troubleshooting. Query: "HINFO 4142559687393037902.3998329434494583584."



Resolution Steps:
[Ref1:https://coredns.io/plugins/loop/#troubleshooting]
[Ref2:https://github.com/coredns/coredns/issues/2790]

1. Edit sudo nano /etc/resolv.conf

nameserver 8.8.8.8

save it.

2.

(base) system@AI-BEAST:/run/systemd$ kubectl get po --all-namespaces
NAMESPACE     NAME                               READY   STATUS             RESTARTS   AGE
kube-system   coredns-5c98db65d4-qv5tm           0/1     CrashLoopBackOff   9          26m
kube-system   coredns-5c98db65d4-sg4q4           0/1     CrashLoopBackOff   9          26m
kube-system   etcd-ai-beast                      1/1     Running            0          25m
kube-system   kube-apiserver-ai-beast            1/1     Running            0          25m
kube-system   kube-controller-manager-ai-beast   1/1     Running            0          25m
kube-system   kube-flannel-ds-amd64-wnjc7        1/1     Running            0          24m
kube-system   kube-proxy-z7s4j                   1/1     Running            0          26m
kube-system   kube-scheduler-ai-beast            1/1     Running            0          25m

COREDNS PODS STILL CRASHING:

Steps:

1.
(base) system@AI-BEAST:/run/systemd$ kubectl delete po coredns-5c98db65d4-qv5tm coredns-5c98db65d4-sg4q4 -n kube-system
pod "coredns-5c98db65d4-qv5tm" deleted
pod "coredns-5c98db65d4-sg4q4" deleted

2.Check the status CoreDNS is running now.

(base) system@AI-BEAST:/run/systemd$ kubectl get po --all-namespaces
NAMESPACE     NAME                               READY   STATUS    RESTARTS   AGE
kube-system   coredns-5c98db65d4-grg4h           1/1     Running   0          12s
kube-system   coredns-5c98db65d4-h59nm           1/1     Running   0          12s
kube-system   etcd-ai-beast                      1/1     Running   0          26m
kube-system   kube-apiserver-ai-beast            1/1     Running   0          26m
kube-system   kube-controller-manager-ai-beast   1/1     Running   0          26m
kube-system   kube-flannel-ds-amd64-wnjc7        1/1     Running   0          25m
kube-system   kube-proxy-z7s4j                   1/1     Running   0          27m
kube-system   kube-scheduler-ai-beast            1/1     Running   0          26m
